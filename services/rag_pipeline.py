from sqlalchemy.orm import Session
from sentence_transformers import SentenceTransformer
from qdrant_client import QdrantClient
from qdrant_client.http.models import SearchParams
from openai import OpenAI
from database.database import SessionLocal
from database.models import Document, DocumentChunk
from services.vectorization import get_embedding_model, get_qdrant_client
from config import COLLECTION_NAME, LLM_MODEL, DEEPSEEK_API_KEY
import logging

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s', level=logging.INFO
)
logger = logging.getLogger(__name__)

# Variables check
if (LLM_MODEL is None) or (COLLECTION_NAME is None) or (DEEPSEEK_API_KEY is None):
    raise ValueError("–ü–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ —Ñ–∞–π–ª .env.")


def vectorize_query(query: str, model: SentenceTransformer) -> list[float]:
    """Vectorizes a single text query."""
    logger.info("Vectorizing user query...")
    query_embedding = model.encode(
        [query],
        normalize_embeddings=True,
        convert_to_tensor=False
    ).tolist()[0]
    logger.info("User query vectorized successfully.")
    return query_embedding

def semantic_search(query_vector: list[float], qdrant_client: QdrantClient, limit_k: int = 7):
    """Performs a semantic search in Qdrant."""
    logger.info("Performing semantic search in Qdrant...")
    search_result = qdrant_client.query_points(
        collection_name=COLLECTION_NAME,
        query=query_vector,
        limit=limit_k,
        with_payload=True,
        search_params=SearchParams(
            exact=False,
            hnsw_ef=100
        )
    ).points
    logger.info("Semantic search completed.")
    return search_result

def retrieve_full_context(qdrant_results, session: Session) -> tuple:
    """Retrieves the full text context from PostgreSQL based on Qdrant results."""
    logger.info("Retrieving full context from PostgreSQL...")
    logger.info(f"qdrant_results: {qdrant_results}")
    try:
        top_document_id = qdrant_results[0].payload.get('document_id')
        logger.info(f"top_document_id: {top_document_id}")
    except (IndexError, KeyError):
        logger.warning("No document ID found in Qdrant results.")
        return " ", None

    relevant_chunk_ids = [
        result.payload.get('chunk_id')
        for result in qdrant_results
        if result.payload.get('document_id') == top_document_id
    ]
    logger.info(f"relevant_chunk_ids: {relevant_chunk_ids}")
    if not relevant_chunk_ids:
        logger.warning("No relevant chunk IDs found.")
        return " ", None

    from sqlalchemy import select
    stmt = (
        select(DocumentChunk.content, Document.web_link)
        .join(Document)
        .where(DocumentChunk.chunk_id.in_(relevant_chunk_ids))
        .order_by(DocumentChunk.chunk_id)
    )
    sql_results = session.execute(stmt).fetchall()

    if not sql_results:
        logger.warning("No results found in PostgreSQL for the given chunk IDs.")
        return " ", None

    full_context = [result.content for result in sql_results]
    web_link = sql_results[0].web_link
    context = "\n\n".join(full_context)
    logger.info("Full context retrieved successfully.")
    return context, web_link

def generate_rag_response(context: str, user_query: str) -> str:
    """Generates a response using the RAG model."""
    logger.info("Generating RAG response...")
    SYSTEM_INSTRUCTIONS = (
        "–í—ã ‚Äî —é—Ä–∏–¥–∏—á–µ—Å–∫–∏–π –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç. –í–∞—à–∞ –∑–∞–¥–∞—á–∞ ‚Äî —Å–∏–Ω—Ç–µ–∑–∏—Ä–æ–≤–∞—Ç—å "
        "–ø–æ–Ω—è—Ç–Ω—ã–π –∏ —Å–≤—è–∑–Ω—ã–π –æ—Ç–≤–µ—Ç –Ω–∞ –≤–æ–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è, –∏—Å–ø–æ–ª—å–∑—É—è "
        "–ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω—ã–π –Ω–∏–∂–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç. –ï—Å–ª–∏ –∫–æ–Ω—Ç–µ–∫—Å—Ç –Ω–µ —Å–æ–¥–µ—Ä–∂–∏—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏, "
        "–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ–π –¥–ª—è –æ—Ç–≤–µ—Ç–∞, –≤—ã –¥–æ–ª–∂–Ω—ã –æ—Ç–≤–µ—Ç–∏—Ç—å: '–ò–∑–≤–∏–Ω–∏—Ç–µ, –≤ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω—ã—Ö "
        "–¥–æ–∫—É–º–µ–Ω—Ç–∞—Ö —Ç–æ—á–Ω—ã–π –æ—Ç–≤–µ—Ç –Ω–µ –Ω–∞–π–¥–µ–Ω. –£—Ç–æ—á–Ω–∏—Ç–µ –≤–æ–ø—Ä–æ—Å' –°–æ—Ö—Ä–∞–Ω—è–π—Ç–µ –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—ã–π —Ç–æ–Ω –∏ "
        "–æ—Ç–≤–µ—á–∞–π—Ç–µ –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ."
    )
    client = OpenAI(api_key=DEEPSEEK_API_KEY, base_url="https://api.deepseek.com")
    try:
        response = client.chat.completions.create(
            model=LLM_MODEL,
            messages=[
                {"role": "system", "content": f"{SYSTEM_INSTRUCTIONS}--- –ö–û–ù–¢–ï–ö–°–¢ ---{context}"},
                {"role": "user", "content": user_query},
            ],
            stream=False,
            temperature=0.8, # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º —Å–ª—É—á–∞–π–Ω–æ—Å—Ç—å (—Å–≤–æ–±–æ–¥—É)
            top_p=0.9,       # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–∏–µ –≤—ã–±–æ—Ä–∞ —Ç–æ–∫–µ–Ω–æ–≤
        )
        if not response:
            logger.error("Error generating response: No response object.")
            return '–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ—Ç–≤–µ—Ç–∞'
        logger.info("RAG response generated successfully.")
        return response.choices[0].message.content # type: ignore
    except Exception as e:
        logger.error(f"An unexpected error occurred during generation: {e}")
        return f"‚ùå –ü—Ä–æ–∏–∑–æ—à–ª–∞ –Ω–µ–ø—Ä–µ–¥–≤–∏–¥–µ–Ω–Ω–∞—è –æ—à–∏–±–∫–∞ –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏: {e}"

def rag_pipeline(user_query: str) -> tuple[str, str | None]:
    import sys
    """The main RAG pipeline."""
    logger.info("Starting RAG pipeline...")
    embedding_model = get_embedding_model()
    qdrant_client = get_qdrant_client()

    query_vector = vectorize_query(user_query, embedding_model)
    qdrant_results = semantic_search(query_vector, qdrant_client)

    with SessionLocal() as session:
        context, web_link = retrieve_full_context(qdrant_results, session)

    if not context.strip():
        logger.warning("Context is empty, returning a default message.")
        return "–ò–∑–≤–∏–Ω–∏—Ç–µ, –≤ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ö —Ç–æ—á–Ω—ã–π –æ—Ç–≤–µ—Ç –Ω–µ –Ω–∞–π–¥–µ–Ω.", None
    
    # -----------------------------------------------------
    # üü¢ –õ–û–ì–ò–ö–ê –ò–ó–ú–ï–†–ï–ù–ò–Ø –†–ê–ó–ú–ï–†–ê –ö–û–ù–¢–ï–ö–°–¢–ê –í –ú–ë üü¢
    # -----------------------------------------------------
    
    # 1. –ò–∑–º–µ—Ä–µ–Ω–∏–µ —Ä–∞–∑–º–µ—Ä–∞ –≤ –±–∞–π—Ç–∞—Ö —Å –∫–æ–¥–∏—Ä–æ–≤–∫–æ–π UTF-8
    size_bytes = len(context.encode('utf-8'))
    
    # 2. –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –±–∞–π—Ç–æ–≤ –≤ –º–µ–≥–∞–±–∞–π—Ç—ã (1 –ú–ë = 1024 * 1024 –±–∞–π—Ç)
    size_mb = size_bytes / (1024 * 1024)
    
    # 3. –í—ã–≤–æ–¥ –≤ –ª–æ–≥–∏
    logger.info(f"üíæ –ö–æ–Ω—Ç–µ–∫—Å—Ç –∏–∑ –±–∞–∑—ã: {size_bytes} –±–∞–π—Ç, —á—Ç–æ —Å–æ—Å—Ç–∞–≤–ª—è–µ—Ç {size_mb:.4f} –ú–ë.")
    
    # -----------------------------------------------------

    final_answer = generate_rag_response(context, user_query)
    logger.info("RAG pipeline finished successfully.")
    return final_answer, web_link
