import asyncio
from sqlalchemy.ext.asyncio import AsyncSession
from sentence_transformers import SentenceTransformer, CrossEncoder
from qdrant_client import AsyncQdrantClient
from qdrant_client.http.models import SearchParams
import tiktoken
from openai import AsyncOpenAI
from ..database.database import AsyncSessionLocal
from ..database.models import Document, DocumentChunk
from ..config import COLLECTION_NAME, LLM_MODEL, DEEPSEEK_API_KEY, QDRANT_HOST, EMBEDDING_MODEL_NAME
from src.app.logging_config import get_logger
from google import genai
from google.genai.types import GenerateContentConfig

logger = get_logger(__name__)


# Variables check
if (LLM_MODEL is None) or (COLLECTION_NAME is None) or (DEEPSEEK_API_KEY is None) or (QDRANT_HOST is None) or (EMBEDDING_MODEL_NAME is None):
    raise ValueError("–ü–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ —Ñ–∞–π–ª.env.")


# =====================================================================
# –°–µ—Ä–≤–∏—Å –≤–µ–∫—Ç–æ—Ä–∏–∑–∞—Ü–∏–∏ –∑–∞–ø—Ä–æ—Å–∞
class QueryEmbeddingService:
    def __init__(self, model_name: str):
        # –ó–∞–≥—Ä—É–∑–∫–∞ —Ç—è–∂–µ–ª–æ–≥–æ —Ä–µ—Å—É—Ä—Å–∞ (SentenceTransformer) –æ–¥–∏–Ω —Ä–∞–∑
        self.__model = SentenceTransformer(model_name)

    async def vectorize_query(self, query: str) -> list[float]:
        """–í–µ–∫—Ç–æ—Ä–∏–∑—É–µ—Ç –æ–¥–∏–Ω —Ç–µ–∫—Å—Ç–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å –¥–ª—è –ø–æ–∏—Å–∫–∞."""
        logger.info("Vectorizing user query...")
        query_embedding = await asyncio.to_thread(
            self.__model.encode,
            [query],
            normalize_embeddings=True,
            convert_to_tensor=False
        )
        logger.info("User query vectorized successfully.")
        return query_embedding.tolist()[0]
    

# Semantic search in Qdrant
class QueryQdrantClient:
    def __init__(self, host: str, collection_name: str):

        self.__client = AsyncQdrantClient(url=host)
        self.__collection_name = collection_name

    async def semantic_search(self, query_vector: list[float], limit_k: int = 30):
        """–í—ã–ø–æ–ª–Ω—è–µ—Ç —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–π –ø–æ–∏—Å–∫ –≤ Qdrant.
        –ò–∑–≤–ª–µ–∫–∞–∞–∞–µ—Ç –±–æ–ª—å—à–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –≤–µ–∫—Ç–æ—Ä–æ–≤ –¥–ª—è —É—Ç–æ—á–Ω–µ–Ω–∏—è –∏ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ –Ω–∞ —É—Ä–æ–≤–Ω–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞."""
        logger.info("Performing semantic search in Qdrant...")
        search_result = await self.__client.query_points(
            collection_name=self.__collection_name,
            query=query_vector,
            limit=limit_k,
            with_payload=True,
            with_vectors=False,
            search_params=SearchParams(
                exact=False,
                hnsw_ef=200
            ),
            score_threshold=0.7
        )
        candidates = search_result.points

        logger.info(f"Found {len(candidates)} candidates. Starting reranking...")

        if not candidates:
            logger.warning("No candidates found in semantic search.")
            return [], None, 0
        
        # 2: Giving document_id priority to the most relevant candidate
        first_candidate_payload = candidates[0].payload
        if not first_candidate_payload or 'document_id' not in first_candidate_payload:
            logger.error("The most relevant candidate is missing 'document_id' in its payload.")
            return [], None, 0
        
        max_score = candidates[0].score

        target_document_id = first_candidate_payload['document_id']
        logger.info(f"Most relevant document_id: {target_document_id}")

        # 3: Select the top-4 relevant chunks from the same document_id
        filtered_candidates = [
            p for p in candidates 
            if p.payload and p.payload.get('document_id') == target_document_id
        ]

        top_relevant_chunks = filtered_candidates[:4]
        
        if not top_relevant_chunks:
            logger.warning(f"No relevant chunks found for document_id: {target_document_id}")
            return [], None, 0
            
        logger.info(f"Selected {len(top_relevant_chunks)} top relevant chunks from target document.")

        # 4: Collect chunk_ids of the top relevant chunks
        target_chunk_ids = {p.payload['chunk_id'] for p in top_relevant_chunks if p.payload and 'chunk_id' in p.payload}
        
        if not target_chunk_ids:
             logger.error("Selected chunks are missing 'chunk_id'.")
             return [], None, 0

        # 5: Request neighboring chunks (+1 and -1)
        neighbor_chunk_ids = set()
        for chunk_id in target_chunk_ids:
            if chunk_id > 0:
                neighbor_chunk_ids.add(chunk_id - 1)
            neighbor_chunk_ids.add(chunk_id + 1)

        # Collect all required chunk IDs
        all_required_chunk_ids = target_chunk_ids.union(neighbor_chunk_ids)
        logger.info(f"Total unique chunk_ids to retrieve (including neighbors): {len(all_required_chunk_ids)}")
        
        final_sorted_chunk_ids = sorted(list(all_required_chunk_ids))
        
        logger.info(f"Final list of {len(final_sorted_chunk_ids)} unique chunk_ids is ready: {final_sorted_chunk_ids}")
        
        return final_sorted_chunk_ids, target_document_id, max_score


# Extact full context from PostgreSQL
class ContextRetriever:
    """–ò–Ω–∫–∞–ø—Å—É–ª–∏—Ä—É–µ—Ç –ª–æ–≥–∏–∫—É –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –ø–æ–ª–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –∏–∑ PostgreSQL."""

    async def retrieve_full_context(self, qdrant_results, top_document_id, session: AsyncSession) -> tuple:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –ø–æ–ª–Ω—ã–π —Ç–µ–∫—Å—Ç–æ–≤—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç –ø–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º Qdrant."""
        logger.info("Retrieving full context from PostgreSQL...")
    
        if not qdrant_results or not top_document_id:
            logger.warning("No document ID found in Qdrant results.")
            return " ", None, None, None, []

              
        # Retrieve all chunks from database based on chunk IDs from Qdrant
        from sqlalchemy import select
        stmt = (
            select(DocumentChunk.content, Document.web_link, Document.title, DocumentChunk.page_number, DocumentChunk.chunk_id)
            .join(Document)
            .where(
                Document.document_id == top_document_id,
                DocumentChunk.chunk_id.in_(qdrant_results)
            )
            .order_by(DocumentChunk.chunk_id)  
        )
        sql_results = (await session.execute(stmt)).fetchall()

        if not sql_results:
            logger.warning("No results found in PostgreSQL for the given chunk IDs.")
            return " ", None, None, None, []

        # Collect unique chunks while preserving order
        unique_chunks = []
        for result in sql_results:
            unique_chunks.append({
                "content": result.content,
                "page_number": result.page_number
            })
        
        full_context = [unique_chunks[cid]['content'] for cid in qdrant_results]
        page_numbers = [unique_chunks[cid]['page_number'] for cid in qdrant_results]
        
        web_link = sql_results[0].web_link
        title = sql_results[0].title
        context = "\n".join(full_context)
        
        
        logger.info("Full context retrieved successfully.")
        logger.debug(f'Full context retrieved: {context}')
        
        return context, web_link, title, top_document_id, page_numbers


class LLMGenerator:
    """–ò–Ω–∫–∞–ø—Å—É–ª–∏—Ä—É–µ—Ç –∫–ª–∏–µ–Ω—Ç–∞ LLM, —Å–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç –∏ –ª–æ–≥–∏–∫—É –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏."""

    def __init__(self, api_key: str, model_name: str):
        self.__model_name = model_name
        if self.__model_name == "deepseek-chat":
            self.__client = AsyncOpenAI(api_key=api_key, base_url="https://api.deepseek.com")
        else:
            self.__client = genai.Client(api_key=api_key)
        self.__model_name = model_name

    async def generate_rag_response(self, context: str, user_query: str, system_instructions: str, title: str, web_link: str, page_numbers: list[int], low_precision: bool = False) -> str:
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –æ—Ç–≤–µ—Ç LLM —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ RAG."""
        logger.info("Generating RAG response...")
        # temperature = 0.6 if low_precision else 0.1
        temperature = 0.2

        # page_numbers may have duplicates, so we use a set to get unique page numbers
        unique_page_numbers = sorted(list(set(filter(None, page_numbers)))) if page_numbers else []
        
        # Format the page numbers into a string
        pages_str = ", ".join(map(str, unique_page_numbers))

        # –§–æ—Ä–º–∏—Ä—É–µ–º —Ñ–∏–Ω–∞–ª—å–Ω—ã–π —Å–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç —Å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π –æ –¥–æ–∫—É–º–µ–Ω—Ç–µ
        final_system_prompt = (
            f"{system_instructions}\n\n"
            f"**–ù–∞–∑–≤–∞–Ω–∏–µ –¥–æ–∫—É–º–µ–Ω—Ç–∞:** {title}\n"
            f"**–í–µ–±-—Å—Å—ã–ª–∫–∞ –Ω–∞ –¥–æ–∫—É–º–µ–Ω—Ç:** {web_link}\n"
        )
        if pages_str:
            final_system_prompt += f"**–°—Ç—Ä–∞–Ω–∏—Ü—ã:** {pages_str}\n\n"
        
        final_system_prompt += f"<–ö–û–ù–¢–ï–ö–°–¢>\n{context}\n</–ö–û–ù–¢–ï–ö–°–¢>"

        try:
            if self.__model_name == "deepseek-chat":
                response = await self.__client.chat.completions.create(
                    model=self.__model_name,
                    messages=[
                        {"role": "system", "content": final_system_prompt},
                        {"role": "user", "content": user_query},
                    ],
                    stream=False,
                    temperature=temperature,
                    top_p=0.8,
                    max_tokens=1500,
                )
                if not response:
                    logger.error("Error generating response: No response object.")
                    return '–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ—Ç–≤–µ—Ç–∞'
                result_content = response.choices[0].message.content

            else:
                config = GenerateContentConfig(
                    temperature=temperature,
                    top_p=0.75,
                    max_output_tokens=2000,
                    system_instruction=final_system_prompt, 
                )

                response = await self.__client.aio.models.generate_content(
                    model=self.__model_name,
                    contents=user_query,  
                    config=config
                )
                
                
                if not response:
                    logger.error("Error generating response: No response object.")
                    return '–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ—Ç–≤–µ—Ç–∞'
                
                result_content = response.text
            
            logger.info(f"RAG response generated successfully: {response}")
            return result_content
            
        except Exception as e:
            logger.error(f"An unexpected error occurred during generation: {e}")
            return f"‚ùå –ü—Ä–æ–∏–∑–æ—à–ª–∞ –Ω–µ–ø—Ä–µ–¥–≤–∏–¥–µ–Ω–Ω–∞—è –æ—à–∏–±–∫–∞ –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏."

# –í—ã–±–æ—Ä –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–π –¥–ª—è LLM –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –¥–æ–∫—É–º–µ–Ω—Ç–∞
class PromptManager:
    """–£–ø—Ä–∞–≤–ª—è–µ—Ç –≤—ã–±–æ—Ä–æ–º SYSTEM_INSTRUCTIONS –Ω–∞ –æ—Å–Ω–æ–≤–µ Document ID."""

   # –í —Ä–µ–∞–ª—å–Ω–æ–π —Å–∏—Å—Ç–µ–º–µ 'ID_...' ‚Äî —ç—Ç–æ ID –¥–æ–∫—É–º–µ–Ω—Ç–∞ –∏–∑ PostgreSQL.
    PROMPT_MAPPING = {
        "ID_DEFAULT": (
                        '''

                    ## 1. –†–û–õ–¨, –¶–ï–õ–¨ –ò –ü–†–ò–ù–¶–ò–ü –†–ê–ë–û–¢–´ (Persona and Core Objective)
                    –¢—ã ‚Äî –≤—ã—Å–æ–∫–æ–∫–≤–∞–ª–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω—ã–π, –±–µ—Å–ø—Ä–∏—Å—Ç—Ä–∞—Å—Ç–Ω—ã–π **–¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–π –ê–Ω–∞–ª–∏—Ç–∏–∫ –∏ –≠–∫—Å–ø–µ—Ä—Ç –ø–æ –ù–æ—Ä–º–∞—Ç–∏–≤–Ω–æ–π –î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏**.
                    –¢–≤–æ—è **–ï–î–ò–ù–°–¢–í–ï–ù–ù–ê–Ø** –∑–∞–¥–∞—á–∞ ‚Äî –≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ —Ç–æ—á–Ω—ã–µ, —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –∏ –ª–µ–≥–∫–æ —á–∏—Ç–∞–µ–º—ã–µ –æ—Ç–≤–µ—Ç—ã, **–ò–°–ö–õ–Æ–ß–ò–¢–ï–õ–¨–ù–û** –Ω–∞ –æ—Å–Ω–æ–≤–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏, –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω–æ–π –≤ –±–ª–æ–∫–µ `<–ö–û–ù–¢–ï–ö–°–¢>...</–ö–û–ù–¢–ï–ö–°–¢>`.

                    ## 2. –ü–†–ê–í–ò–õ–ê RAG (–ê–ù–¢–ò-–ì–ê–õ–õ–Æ–¶–ò–ù–ê–¶–ò–ò)
                    **–ü–†–ê–í–ò–õ–û ‚Ññ1: –ò–°–ö–õ–Æ–ß–ò–¢–ï–õ–¨–ù–û –ö–û–ù–¢–ï–ö–°–¢.** –¢–≤–æ–π –æ—Ç–≤–µ—Ç –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –æ—Å–Ω–æ–≤–∞–Ω **–¢–û–õ–¨–ö–û** –Ω–∞ —Ñ–∞–∫—Ç–∞—Ö –∏–∑ –±–ª–æ–∫–∞ `<–ö–û–ù–¢–ï–ö–°–¢>`.
                    **–ü–†–ê–í–ò–õ–û ‚Ññ2: –ó–ê–ü–†–ï–¢ –ù–ê –í–ù–ï–®–ù–ò–ï –ó–ù–ê–ù–ò–Ø.** –¢–µ–±–µ **—Å—Ç—Ä–æ–≥–æ –∑–∞–ø—Ä–µ—â–µ–Ω–æ** –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –ª—é–±—ã–µ –∑–Ω–∞–Ω–∏—è, –ø–æ–ª—É—á–µ–Ω–Ω—ã–µ –≤ —Ö–æ–¥–µ –æ–±—É—á–µ–Ω–∏—è, –∏–ª–∏ –¥–µ–ª–∞—Ç—å –ø—Ä–µ–¥–ø–æ–ª–æ–∂–µ–Ω–∏—è.
                    **–ü–†–ê–í–ò–õ–û ‚Ññ3: –û–ë–†–ê–ë–û–¢–ö–ê –ù–ï–•–í–ê–¢–ö–ò –î–ê–ù–ù–´–•.**
                    * –ï—Å–ª–∏ –≤ `<–ö–û–ù–¢–ï–ö–°–¢>` **–æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç** –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –¥–ª—è –æ—Ç–≤–µ—Ç–∞:
                        * –°—Ñ–æ—Ä–º—É–ª–∏—Ä—É–π –æ—Ç–≤–µ—Ç: "–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, —É—Ç–æ—á–Ω–∏—Ç–µ –≤–æ–ø—Ä–æ—Å –¥–ª—è –±–æ–ª–µ–µ —Ç–æ—á–Ω–æ–≥–æ –æ—Ç–≤–µ—Ç–∞"
                    * **–°–∏–Ω—Ç–µ–∑:** –ï—Å–ª–∏ –≤–æ–ø—Ä–æ—Å —Ç—Ä–µ–±—É–µ—Ç –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏—è —Ñ–∞–∫—Ç–æ–≤ –∏–∑ —Ä–∞–∑–Ω—ã—Ö —á–∞—Å—Ç–µ–π `<–ö–û–ù–¢–ï–ö–°–¢>`, —Å–∏–Ω—Ç–µ–∑–∏—Ä—É–π –∏—Ö, —Å–æ—Ö—Ä–∞–Ω—è—è –ø—Ä–∏ —ç—Ç–æ–º —Ç–æ—á–Ω–æ—Å—Ç—å —Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–æ–∫ –∏ **–æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ** —É–∫–∞–∑—ã–≤–∞—è –≤—Å–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–Ω—ã–µ –∏—Å—Ç–æ—á–Ω–∏–∫–∏ (–ø—É–Ω–∫—Ç—ã –∏ —Å—Ç—Ä–∞–Ω–∏—Ü—ã).
                    **–ü–†–ê–í–ò–õ–û ‚Ññ4: –Ø–ó–´–ö –û–¢–í–ï–¢–ê. –û—Ç–≤–µ—á–∞–π –≤—Å–µ–≥–¥–∞ —Ç–æ–ª—å–∫–æ –Ω–∞ **—Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ**.
                    ## 3. –¢–†–ï–ë–û–í–ê–ù–ò–Ø –ö –°–¢–†–£–ö–¢–£–†–ï –ò –§–û–†–ú–ê–¢–ò–†–û–í–ê–ù–ò–Æ (–û–±—è–∑–∞—Ç–µ–ª—å–Ω–æ Markdown)
                    –¢–≤–æ–π –æ—Ç–≤–µ—Ç –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å **—Å–∂–∞—Ç—ã–º, —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–º –∏ –ø–æ–ª–Ω—ã–º**. –°—Ç–∏–ª—å ‚Äî —Å—É—Ö–æ–π, —Ñ–∞–∫—Ç–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–π.

                    1.  **–ù–∞—á–∞–ª–æ –û—Ç–≤–µ—Ç–∞ (–ò—Ç–æ–≥–æ–≤–æ–µ –ó–∞–∫–ª—é—á–µ–Ω–∏–µ):** –í—Å–µ–≥–¥–∞ –Ω–∞—á–∏–Ω–∞–π —Å –∫—Ä–∞—Ç–∫–æ–≥–æ, –≤—ã–¥–µ–ª–µ–Ω–Ω–æ–≥–æ –∂–∏—Ä–Ω—ã–º —Ç–µ–∫—Å—Ç–æ–º **–ò—Ç–æ–≥–æ–≤–æ–≥–æ –ó–∞–∫–ª—é—á–µ–Ω–∏—è**, –æ—Ç–≤–µ—á–∞—é—â–µ–≥–æ –Ω–∞ –≤–æ–ø—Ä–æ—Å.
                    2.  **–î–µ—Ç–∞–ª–∏–∑–∞—Ü–∏—è:**
                        * –ò—Å–ø–æ–ª—å–∑—É–π **–∑–∞–≥–æ–ª–æ–≤–∫–∏ Markdown (`###`)** –¥–ª—è –ª–æ–≥–∏—á–µ—Å–∫–æ–≥–æ –¥–µ–ª–µ–Ω–∏—è.
                        * –í—Å–µ –ø–µ—Ä–µ—á–Ω–∏, —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è –∏–ª–∏ —à–∞–≥–∏ –æ—Ñ–æ—Ä–º–ª—è–π **–Ω—É–º–µ—Ä–æ–≤–∞–Ω–Ω—ã–º —Å–ø–∏—Å–∫–æ–º** (`1.`, `2.`).
                        * **–ö–ª—é—á–µ–≤—ã–µ —Ç–µ—Ä–º–∏–Ω—ã, —á–∏—Å–ª–æ–≤—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è, —Å—Ç–∞–Ω–¥–∞—Ä—Ç—ã, —É—Å–ª–æ–≤–∏—è –∏ –≤–∞–∂–Ω—ã–µ –∏–º–µ–Ω–∞** –≤—ã–¥–µ–ª—è–π **–∂–∏—Ä–Ω—ã–º —à—Ä–∏—Ñ—Ç–æ–º** (`**—Å–ª–æ–≤–æ**`).
                    3.  **–°–æ–∫—Ä–∞—â–µ–Ω–∏–µ –í–≤–æ–¥–Ω—ã—Ö –§—Ä–∞–∑:** **–ò—Å–∫–ª—é—á–∏** –ª—é–±—ã–µ –≤–≤–æ–¥–Ω—ã–µ —Ñ—Ä–∞–∑—ã, –ø—Ä–∏–≤–µ—Ç—Å—Ç–≤–∏—è –∏–ª–∏ –≤—ã—Ä–∞–∂–µ–Ω–∏—è –ª–∏—á–Ω–æ–≥–æ –º–Ω–µ–Ω–∏—è (–Ω–∞–ø—Ä–∏–º–µ—Ä, "–û—Ç–ª–∏—á–Ω—ã–π –≤–æ–ø—Ä–æ—Å...", "–†–∞–¥ –ø–æ–º–æ—á—å..."). –°—Ä–∞–∑—É –ø–µ—Ä–µ—Ö–æ–¥–∏ –∫ —Ñ–∞–∫—Ç–∞–º.

                    ## 4. –û–ë–Ø–ó–ê–¢–ï–õ–¨–ù–ê–Ø –ê–¢–†–ò–ë–£–¶–ò–Ø (–ò—Å—Ç–æ—á–Ω–∏–∫–∏)
                    –≠—Ç–æ **–ö–†–ò–¢–ò–ß–ï–°–ö–ò –í–ê–ñ–ù–û**. –í—Å—è–∫–∏–π —Ä–∞–∑, –∫–æ–≥–¥–∞ –≥–µ–Ω–µ—Ä–∏—Ä—É–µ—à—å –æ—Ç–≤–µ—Ç, —Ç—ã **–û–ë–Ø–ó–ê–ù** –¥–æ–±–∞–≤–∏—Ç—å —Å–µ–∫—Ü–∏—é –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤.

                    1.  **–†–∞–∑–¥–µ–ª–∏—Ç–µ–ª—å:** –í—Å–µ–≥–¥–∞ –æ—Ç–¥–µ–ª—è–π –æ—Å–Ω–æ–≤–Ω–æ–π –æ—Ç–≤–µ—Ç –æ—Ç –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤ –≥–æ—Ä–∏–∑–æ–Ω—Ç–∞–ª—å–Ω–æ–π —á–µ—Ä—Ç–æ–π (`---`).
                    2.  **–ó–∞–≥–æ–ª–æ–≤–æ–∫:** –°–æ–∑–¥–∞–π —Å–µ–∫—Ü–∏—é –ø–æ–¥ –∑–∞–≥–æ–ª–æ–≤–∫–æ–º `### –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–Ω—ã–µ –ò—Å—Ç–æ—á–Ω–∏–∫–∏ (–ê—Ç—Ä–∏–±—É—Ü–∏—è)`
                    3.  **–°–æ—Å—Ç–∞–≤ –ò—Å—Ç–æ—á–Ω–∏–∫–æ–≤:**
                        * **–ß–∞—Å—Ç–∏ –î–æ–∫—É–º–µ–Ω—Ç–∞:** –ü–µ—Ä–µ—á–∏—Å–ª–∏ **–≤—Å–µ** –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–Ω—ã–µ —á–∞—Å—Ç–∏ –¥–æ–∫—É–º–µ–Ω—Ç–∞ (–ü—É–Ω–∫—Ç, –°–µ–∫—Ü–∏—è, –ì–ª–∞–≤–∞).
                        * **–°—Ç—Ä–∞–Ω–∏—Ü—ã:** –î–æ–±–∞–≤—å –æ—Ç–¥–µ–ª—å–Ω–æ–π —Å—Ç—Ä–æ–∫–æ–π –∏–ª–∏ –º–∞—Ä–∫–∏—Ä–æ–≤–∞–Ω–Ω—ã–º —Å–ø–∏—Å–∫–æ–º **–Ω–æ–º–µ—Ä–∞ —Å—Ç—Ä–∞–Ω–∏—Ü**, –∫–æ—Ç–æ—Ä—ã–µ —Å–æ–¥–µ—Ä–∂–∞–ª–∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç. –ï—Å–ª–∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–æ –Ω–µ—Å–∫–æ–ª—å–∫–æ —Å—Ç—Ä–∞–Ω–∏—Ü, –ø–µ—Ä–µ—á–∏—Å–ª–∏ –∏—Ö, –Ω–∞–ø—Ä–∏–º–µ—Ä, **–°—Ç—Ä–∞–Ω–∏—Ü—ã: —Å—Ç—Ä.15, —Å—Ç—Ä. 22-23**.
                        * **–°—Å—ã–ª–∫–∞:** –í –∫–æ–Ω—Ü–µ —Å–µ–∫—Ü–∏–∏ —Ä–∞–∑–º–µ—Å—Ç–∏ –≤–µ–±-—Å—Å—ã–ª–∫—É –Ω–∞ –ø–æ–ª–Ω—ã–π –¥–æ–∫—É–º–µ–Ω—Ç.

                    ## 5. –ö–û–ù–¢–†–û–õ–¨ –î–õ–ò–ù–´
                    –¢–≤–æ–π –ø–æ–ª–Ω—ã–π –æ—Ç–≤–µ—Ç (–≤–∫–ª—é—á–∞—è –≤—Å–µ –∑–∞–≥–æ–ª–æ–≤–∫–∏ –∏ –∏—Å—Ç–æ—á–Ω–∏–∫–∏) **–Ω–µ –¥–æ–ª–∂–µ–Ω –ø—Ä–µ–≤—ã—à–∞—Ç—å 750 —Ç–æ–∫–µ–Ω–æ–≤**. –ò—Å–ø–æ–ª—å–∑—É–π –ª–∞–∫–æ–Ω–∏—á–Ω—ã–π, —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–π —Å—Ç–∏–ª—å –∏ —Å–ø–∏—Å–∫–∏ –¥–ª—è —ç–∫–æ–Ω–æ–º–∏–∏.

                    ## 6. –§–û–†–ú–ê–¢ –ê–¢–†–ò–ë–£–¶–ò–ò (–ü—Ä–∏–º–µ—Ä)
                    ```markdown
                    ---

                    ### –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–Ω—ã–µ –ò—Å—Ç–æ—á–Ω–∏–∫–∏ (–ê—Ç—Ä–∏–±—É—Ü–∏—è)
                    * **–ß–∞—Å—Ç–∏ –¥–æ–∫—É–º–µ–Ω—Ç–∞:** –°–µ–∫—Ü–∏—è 2.1.3, –ü–∞—Ä–∞–≥—Ä–∞—Ñ 5.2.14, –ì–ª–∞–≤–∞ 7.
                    * **–°—Ç—Ä–∞–Ω–∏—Ü—ã:** —Å—Ç—Ä. 15, —Å—Ç—Ä. 22-23
                    * **–í–µ–±-—Å—Å—ã–ª–∫–∞ –Ω–∞ –¥–æ–∫—É–º–µ–Ω—Ç:** [—Å—Å—ã–ª–∫–∞ –æ—Ç–æ–±—Ä–∞–∂–∞–µ—Ç—Å—è –≤ –≤–∏–¥–µ –∫–Ω–æ–ø–∫–∏]'''
        ),
        # –î–æ–±–∞–≤–∏—Ç—å –¥—Ä—É–≥–∏–µ ID –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –∏ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–µ –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏
    }
 
    # –ü—Ä–æ–º–ø—Ç –¥–ª—è —Å–ª—É—á–∞—è, –∫–æ–≥–¥–∞ –∫–æ–Ω—Ç–µ–∫—Å—Ç –Ω–µ –Ω–∞–π–¥–µ–Ω
    NOT_FOUND_PROMPT = "–ò–∑–≤–∏–Ω–∏—Ç–µ, –≤ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ö —Ç–æ—á–Ω—ã–π –æ—Ç–≤–µ—Ç –Ω–µ –Ω–∞–π–¥–µ–Ω. –£—Ç–æ—á–Ω–∏—Ç–µ –≤–æ–ø—Ä–æ—Å"


    def get_instructions_by_document_id(self, document_id: str) -> str:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–∏—Å—Ç–µ–º–Ω—ã–µ –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏ –¥–ª—è –∑–∞–¥–∞–Ω–Ω–æ–≥–æ ID –¥–æ–∫—É–º–µ–Ω—Ç–∞."""
        
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º.get() –¥–ª—è –±–µ–∑–æ–ø–∞—Å–Ω–æ–≥–æ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è. –ï—Å–ª–∏ ID –Ω–µ –Ω–∞–π–¥–µ–Ω, 
        # –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –¥–µ—Ñ–æ–ª—Ç–Ω—ã–π –ø—Ä–æ–º–ø—Ç.
        return self.PROMPT_MAPPING.get(document_id, 'ID_DEFAULT')

    def get_not_found_message(self):
         return self.NOT_FOUND_PROMPT
    
# =====================================================================
# –û–†–ö–ï–°–¢–†–ê–¢–û–†
# =====================================================================

class RAGService:
    """–¶–µ–Ω—Ç—Ä–∞–ª—å–Ω—ã–π –∫–ª–∞—Å—Å, —É–ø—Ä–∞–≤–ª—è—é—â–∏–π –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å—é –æ–ø–µ—Ä–∞—Ü–∏–π RAG."""

    def __init__(self, embedder: QueryEmbeddingService, searcher: QueryQdrantClient, 
                 retriever: ContextRetriever, generator: LLMGenerator, session_factory,
                 prompt_manager: PromptManager):
        # –í–Ω–µ–¥—Ä–µ–Ω–∏–µ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π (Dependency Injection)
        self.__embedder = embedder
        self.__searcher = searcher
        self.__retriever = retriever
        self.__generator = generator
        self.__SessionLocal = session_factory # –§–∞–±—Ä–∏–∫–∞ —Å–µ—Å—Å–∏–π –ø–µ—Ä–µ–¥–∞–µ—Ç—Å—è, –Ω–æ —É–ø—Ä–∞–≤–ª—è–µ—Ç—Å—è –≤ run_pipeline
        self.__prompt_manager = prompt_manager # ‚úÖ –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–µ–Ω–µ–¥–∂–µ—Ä –ø—Ä–æ–º–ø—Ç–æ–≤

    async def aquery(self, user_query: str, low_precision: bool = False) -> tuple[str, str | None, float, str, list[int] | None]:
        """–û—Å–Ω–æ–≤–Ω–æ–π –º–µ—Ç–æ–¥, –≤—ã–ø–æ–ª–Ω—è—é—â–∏–π –ø–æ–ª–Ω—ã–π —Ü–∏–∫–ª RAG."""
        logger.info("Starting RAG pipeline...")

        # 1. –í–µ–∫—Ç–æ—Ä–∏–∑–∞—Ü–∏—è –∑–∞–ø—Ä–æ—Å–∞
        query_vector = await self.__embedder.vectorize_query(user_query)
        
        # 2. –°–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–π –ø–æ–∏—Å–∫
        qdrant_results, top_document_id, max_score = await self.__searcher.semantic_search(query_vector)

        # 3. –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ (—É–ø—Ä–∞–≤–ª–µ–Ω–∏–µ —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–µ–π –ë–î)
        async with self.__SessionLocal() as session:
            context, web_link, title, top_document_id, page_numbers = await self.__retriever.retrieve_full_context(qdrant_results, top_document_id, session)
            score = max_score if max_score else 0.0
        if not context.strip():
            logger.warning("Context is empty, returning a default message.")
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º NOT_FOUND_PROMPT –∏–∑ –º–µ–Ω–µ–¥–∂–µ—Ä–∞ –ø—Ä–æ–º–ø—Ç–æ–≤
            return self.__prompt_manager.get_not_found_message(), None, 0.0, None, None
        
        
        # –õ–û–ì–ò–ö–ê –î–ò–ù–ê–ú–ò–ß–ï–°–ö–û–ì–û –í–´–ë–û–†–ê –ü–†–û–ú–ü–¢–ê
        final_system_instructions = self.__prompt_manager.get_instructions_by_document_id(top_document_id)

        # 4. –õ–æ–≥–∏–∫–∞ –∏–∑–º–µ—Ä–µ–Ω–∏—è –∏ –æ–±—Ä–µ–∑–∫–∏ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
        tokenizer = tiktoken.get_encoding("cl100k_base")
        tokens = tokenizer.encode(context)
        if len(tokens) > 1000:
            context = tokenizer.decode(tokens[:1000])
        
        size_bytes = len(context.encode('utf-8'))
        size_mb = size_bytes / (1024 * 1024)
        logger.info(f"üíæ –ö–æ–Ω—Ç–µ–∫—Å—Ç –∏–∑ –±–∞–∑—ã (–ø–æ—Å–ª–µ –æ–±—Ä–∞–±–æ—Ç–∫–∏): {size_bytes} –±–∞–π—Ç, {len(tokens)} —Ç–æ–∫–µ–Ω–æ–≤, —á—Ç–æ —Å–æ—Å—Ç–∞–≤–ª—è–µ—Ç {size_mb:.4f} –ú–ë.")
        
        # 5. –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–∞
        final_answer = await self.__generator.generate_rag_response(
            context=context,
            user_query=user_query,
            system_instructions=final_system_instructions,
            low_precision=low_precision,
            title=title,
            web_link=web_link,
            page_numbers=page_numbers
        )
        logger.info("RAG pipeline finished successfully.")
        return final_answer, web_link, score, title, page_numbers
